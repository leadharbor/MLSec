{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CleverHansSetup.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWotX_uulM6x",
        "colab_type": "code",
        "outputId": "f408576f-c4ff-4bec-ed11-bfde63eddeb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/path/to/your/folder', force_remount=True)\n",
        "root_dir = \"/your/root\"\n",
        "base_dir = root_dir + 'GEEEE/archive/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkNzhHxWR2mr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31e47403-2d1c-4dd0-c518-73ef7167a751"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaMOArm4lfg3",
        "colab_type": "code",
        "outputId": "3b02a57e-f0c9-4079-d532-86fca58ffe88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "#Puts the files in your base dir, for me /content\n",
        "!git clone https://github.com/tensorflow/cleverhans"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cleverhans'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 12564 (delta 4), reused 6 (delta 0), pack-reused 12553\n",
            "Receiving objects: 100% (12564/12564), 5.63 MiB | 25.40 MiB/s, done.\n",
            "Resolving deltas: 100% (8896/8896), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEtM2zaCnD8n",
        "colab_type": "code",
        "outputId": "ea54fb8b-502c-4f65-9694-054eb021f4a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd cleverhans\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/cleverhans\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_-nqATjnHys",
        "colab_type": "code",
        "outputId": "3c7c4186-b4bf-4a28-b501-d1accb5390b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "pip install -e ."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/cleverhans\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (1.3.7)\n",
            "Collecting pycodestyle (from cleverhans==3.0.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (1.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (3.0.3)\n",
            "Collecting mnist~=0.2 (from cleverhans==3.0.1)\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (1.16.4)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (0.6.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (2.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (0.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->cleverhans==3.0.1) (41.0.1)\n",
            "Installing collected packages: pycodestyle, mnist, cleverhans\n",
            "  Running setup.py develop for cleverhans\n",
            "Successfully installed cleverhans mnist-0.2.2 pycodestyle-2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX-fYlmEgXaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/src/cleverhans')\n",
        "import cleverhans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBAqvzwDkBAH",
        "colab_type": "code",
        "outputId": "5fc42da4-1042-4989-cd97-490d652005c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!python -c \"import cleverhans; print (cleverhans.__file__)\"\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/cleverhans/cleverhans/__init__.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVqcy8MTlpeJ",
        "colab_type": "code",
        "outputId": "7ba4dd0e-a060-4b29-8df3-13886977327f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip freeze | grep scipy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scipy==1.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5gC79lhmJ3W",
        "colab_type": "code",
        "outputId": "996fc628-601d-4812-d402-89c57289d2cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "!pip install scipy==1.3.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.3.0\n",
            "  Using cached https://files.pythonhosted.org/packages/72/4c/5f81e7264b0a7a8bd570810f48cd346ba36faedbd2ba255c873ad556de76/scipy-1.3.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy==1.3.0) (1.16.4)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "  Found existing installation: scipy 1.1.0\n",
            "    Uninstalling scipy-1.1.0:\n",
            "      Successfully uninstalled scipy-1.1.0\n",
            "Successfully installed scipy-1.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8yDV9-YtsMh",
        "colab_type": "code",
        "outputId": "ed9a2e3f-5048-4a50-9075-d26c228f39b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/cleverhans\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFEqgVuNSW83",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51e6322e-a972-4416-9ab0-f2fd50d1d32e"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD4NJzyGSZY0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc418bdd-52df-4334-fabd-de3d25e86be8"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cleverhans  data  datasets  facenet  lfw.tgz  models  pairs.txt  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1C0w3U7tuWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r models /content/cleverhans/examples/facenet_adversarial_faces/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIrW9mfUueHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r datasets /content/cleverhans/examples/facenet_adversarial_faces/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik7mJLTASicz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r data /content/cleverhans/examples/facenet_adversarial_faces/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kznUuPel0FPh",
        "colab_type": "code",
        "outputId": "5d890d8c-3247-4b5c-c301-a71e6c3c44eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2379
        }
      },
      "source": [
        "!cat /content/cleverhans/examples/facenet_adversarial_faces/facenet_fgsm.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "import facenet\n",
            "\n",
            "import tensorflow as tf\n",
            "import numpy as np\n",
            "from cleverhans.model import Model\n",
            "from cleverhans.attacks import FastGradientMethod\n",
            "\n",
            "import set_loader\n",
            "\n",
            "\n",
            "class InceptionResnetV1Model(Model):\n",
            "  #CHANGED HERE\n",
            "  model_path = \"models/facenet/20180402-114759/20180402-114759.pb\"\n",
            "\n",
            "  def __init__(self):\n",
            "    super(InceptionResnetV1Model, self).__init__(scope='model')\n",
            "\n",
            "    # Load Facenet CNN\n",
            "    facenet.load_model(self.model_path)\n",
            "    # Save input and output tensors references\n",
            "    graph = tf.get_default_graph()\n",
            "    self.face_input = graph.get_tensor_by_name(\"input:0\")\n",
            "    self.embedding_output = graph.get_tensor_by_name(\"embeddings:0\")\n",
            "\n",
            "  def convert_to_classifier(self):\n",
            "    # Create victim_embedding placeholder\n",
            "    \n",
            "    self.victim_embedding_input = tf.placeholder(\n",
            "        tf.float32,\n",
            "        #CHANGED HERE\n",
            "        shape=(None, 512))\n",
            "\n",
            "    # Squared Euclidean Distance between embeddings\n",
            "    distance = tf.reduce_sum(\n",
            "        tf.square(self.embedding_output - self.victim_embedding_input),\n",
            "        axis=1)\n",
            "\n",
            "    # Convert distance to a softmax vector\n",
            "    # 0.99 out of 4 is the distance threshold for the Facenet CNN\n",
            "    threshold = 0.99\n",
            "    score = tf.where(\n",
            "        distance > threshold,\n",
            "        0.5 + ((distance - threshold) * 0.5) / (4.0 - threshold),\n",
            "        0.5 * distance / threshold)\n",
            "    reverse_score = 1.0 - score\n",
            "    self.softmax_output = tf.transpose(tf.stack([reverse_score, score]))\n",
            "\n",
            "    # Save softmax layer\n",
            "    self.layer_names = []\n",
            "    self.layers = []\n",
            "    self.layers.append(self.softmax_output)\n",
            "    self.layer_names.append('probs')\n",
            "\n",
            "  def fprop(self, x, set_ref=False):\n",
            "    return dict(zip(self.layer_names, self.layers))\n",
            "\n",
            "\n",
            "with tf.Graph().as_default():\n",
            "  with tf.Session() as sess:\n",
            "    # Load model\n",
            "    model = InceptionResnetV1Model()\n",
            "    # Convert to classifier\n",
            "    model.convert_to_classifier()\n",
            "\n",
            "    # Load pairs of faces and their labels in one-hot encoding\n",
            "    faces1, faces2, labels = set_loader.load_testset(1000)\n",
            "\n",
            "    # Create victims' embeddings using Facenet itself\n",
            "    graph = tf.get_default_graph()\n",
            "    phase_train_placeholder = graph.get_tensor_by_name(\"phase_train:0\")\n",
            "    feed_dict = {model.face_input: faces2,\n",
            "                 phase_train_placeholder: False}\n",
            "    victims_embeddings = sess.run(\n",
            "        model.embedding_output, feed_dict=feed_dict)\n",
            "\n",
            "    # Define FGSM for the model\n",
            "    steps = 1\n",
            "    eps = 0.01\n",
            "    alpha = eps / steps\n",
            "    fgsm = FastGradientMethod(model)\n",
            "    fgsm_params = {'eps': alpha,\n",
            "                   'clip_min': 0.,\n",
            "                   'clip_max': 1.}\n",
            "    adv_x = fgsm.generate(model.face_input, **fgsm_params)\n",
            "\n",
            "    # Run FGSM\n",
            "    adv = faces1\n",
            "    for i in range(steps):\n",
            "      print(\"FGSM step \" + str(i + 1))\n",
            "      feed_dict = {model.face_input: adv,\n",
            "                   model.victim_embedding_input: victims_embeddings,\n",
            "                   phase_train_placeholder: False}\n",
            "      adv = sess.run(adv_x, feed_dict=feed_dict)\n",
            "\n",
            "    # Test accuracy of the model\n",
            "    batch_size = graph.get_tensor_by_name(\"batch_size:0\")\n",
            "\n",
            "    feed_dict = {model.face_input: faces1,\n",
            "                 model.victim_embedding_input: victims_embeddings,\n",
            "                 phase_train_placeholder: False,\n",
            "                 batch_size: 64}\n",
            "    real_labels = sess.run(model.softmax_output, feed_dict=feed_dict)\n",
            "\n",
            "    accuracy = np.mean(\n",
            "        (np.argmax(labels, axis=-1)) == (np.argmax(real_labels, axis=-1))\n",
            "    )\n",
            "    print('Accuracy: ' + str(accuracy * 100) + '%')\n",
            "\n",
            "    # Test accuracy against adversarial examples\n",
            "    feed_dict = {model.face_input: adv,\n",
            "                 model.victim_embedding_input: victims_embeddings,\n",
            "                 phase_train_placeholder: False,\n",
            "                 batch_size: 64}\n",
            "    adversarial_labels = sess.run(\n",
            "        model.softmax_output, feed_dict=feed_dict)\n",
            "\n",
            "    same_faces_index = np.where((np.argmax(labels, axis=-1) == 0))\n",
            "    different_faces_index = np.where((np.argmax(labels, axis=-1) == 1))\n",
            "\n",
            "    accuracy = np.mean(\n",
            "        (np.argmax(labels[same_faces_index], axis=-1)) ==\n",
            "        (np.argmax(adversarial_labels[same_faces_index], axis=-1))\n",
            "    )\n",
            "    print('Accuracy against adversarial examples for '\n",
            "          + 'same person faces (dodging): '\n",
            "          + str(accuracy * 100)\n",
            "          + '%')\n",
            "\n",
            "    accuracy = np.mean(\n",
            "        (np.argmax(labels[different_faces_index], axis=-1)) == (\n",
            "            np.argmax(adversarial_labels[different_faces_index], axis=-1))\n",
            "    )\n",
            "    print('Accuracy against adversarial examples for '\n",
            "          + 'different people faces (impersonation): '\n",
            "          + str(accuracy * 100)\n",
            "          + '%')"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBTsrY35nUrC",
        "colab_type": "code",
        "outputId": "65583936-acad-4550-91d0-40cbf8620d0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile /content/cleverhans/examples/facenet_adversarial_faces/facenet_fgsm.py\n",
        "import facenet\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from cleverhans.model import Model\n",
        "from cleverhans.attacks import FastGradientMethod\n",
        "\n",
        "import set_loader\n",
        "\n",
        "\n",
        "class InceptionResnetV1Model(Model):\n",
        "  #CHANGED HERE\n",
        "  model_path = \"models/facenet/20180402-114759/20180402-114759.pb\"\n",
        "  #model_path = \"models/facenet/20170512-110547/20170512-110547.pb\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(InceptionResnetV1Model, self).__init__(scope='model')\n",
        "\n",
        "    # Load Facenet CNN\n",
        "    facenet.load_model(self.model_path)\n",
        "    # Save input and output tensors references\n",
        "    graph = tf.get_default_graph()\n",
        "    self.face_input = graph.get_tensor_by_name(\"input:0\")\n",
        "    self.embedding_output = graph.get_tensor_by_name(\"embeddings:0\")\n",
        "\n",
        "  def convert_to_classifier(self):\n",
        "    # Create victim_embedding placeholder\n",
        "    \n",
        "    self.victim_embedding_input = tf.placeholder(\n",
        "        tf.float32,\n",
        "        #CHANGED HERE some models have 512 others have 128\n",
        "        shape=(None, 512))\n",
        "\n",
        "    # Squared Euclidean Distance between embeddings\n",
        "    distance = tf.reduce_sum(\n",
        "        tf.square(self.embedding_output - self.victim_embedding_input),\n",
        "        axis=1)\n",
        "\n",
        "    # Convert distance to a softmax vector\n",
        "    # 0.99 out of 4 is the distance threshold for the Facenet CNN\n",
        "    threshold = 0.99\n",
        "    score = tf.where(\n",
        "        distance > threshold,\n",
        "        0.5 + ((distance - threshold) * 0.5) / (4.0 - threshold),\n",
        "        0.5 * distance / threshold)\n",
        "    reverse_score = 1.0 - score\n",
        "    self.softmax_output = tf.transpose(tf.stack([reverse_score, score]))\n",
        "\n",
        "    # Save softmax layer\n",
        "    self.layer_names = []\n",
        "    self.layers = []\n",
        "    self.layers.append(self.softmax_output)\n",
        "    #CHANGED HERE to fit with new Model API\n",
        "    self.layer_names.append('logits')\n",
        "\n",
        "  def fprop(self, x, set_ref=False):\n",
        "    return dict(zip(self.layer_names, self.layers))\n",
        "\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "  with tf.Session() as sess:\n",
        "    # Load model\n",
        "    model = InceptionResnetV1Model()\n",
        "    # Convert to classifier\n",
        "    model.convert_to_classifier()\n",
        "\n",
        "    # Load pairs of faces and their labels in one-hot encoding\n",
        "    #CHANGED HERE reduced size of testset because of OOM errors 1000 to 250\n",
        "    faces1, faces2, labels = set_loader.load_testset(333)\n",
        "\n",
        "    # Create victims' embeddings using Facenet itself\n",
        "    graph = tf.get_default_graph()\n",
        "    phase_train_placeholder = graph.get_tensor_by_name(\"phase_train:0\")\n",
        "    feed_dict = {model.face_input: faces2,\n",
        "                 phase_train_placeholder: False}\n",
        "    victims_embeddings = sess.run(\n",
        "        model.embedding_output, feed_dict=feed_dict)\n",
        "\n",
        "    # Define FGSM for the model\n",
        "    steps = 1\n",
        "    eps = 0.01\n",
        "    alpha = eps / steps\n",
        "    fgsm = FastGradientMethod(model)\n",
        "    fgsm_params = {'eps': alpha,\n",
        "                   'clip_min': 0.,\n",
        "                   'clip_max': 1.}\n",
        "    adv_x = fgsm.generate(model.face_input, **fgsm_params)\n",
        "\n",
        "    # Run FGSM\n",
        "    adv = faces1\n",
        "    for i in range(steps):\n",
        "      print(\"FGSM step \" + str(i + 1))\n",
        "      feed_dict = {model.face_input: adv,\n",
        "                   model.victim_embedding_input: victims_embeddings,\n",
        "                   phase_train_placeholder: False}\n",
        "      adv = sess.run(adv_x, feed_dict=feed_dict)\n",
        "\n",
        "    # Test accuracy of the model\n",
        "    batch_size = graph.get_tensor_by_name(\"batch_size:0\")\n",
        "    #CHANGED HERE batch_size: 32 from 64\n",
        "    feed_dict = {model.face_input: faces1,\n",
        "                 model.victim_embedding_input: victims_embeddings,\n",
        "                 phase_train_placeholder: False,\n",
        "                 batch_size: 64}\n",
        "    real_labels = sess.run(model.softmax_output, feed_dict=feed_dict)\n",
        "\n",
        "    accuracy = np.mean(\n",
        "        (np.argmax(labels, axis=-1)) == (np.argmax(real_labels, axis=-1))\n",
        "    )\n",
        "    print('Accuracy: ' + str(accuracy * 100) + '%')\n",
        "\n",
        "    # Test accuracy against adversarial examples\n",
        "    #CHANGED HERE batch_size: 32 from 64\n",
        "    feed_dict = {model.face_input: adv,\n",
        "                 model.victim_embedding_input: victims_embeddings,\n",
        "                 phase_train_placeholder: False,\n",
        "                 batch_size: 64}\n",
        "    adversarial_labels = sess.run(\n",
        "        model.softmax_output, feed_dict=feed_dict)\n",
        "\n",
        "    same_faces_index = np.where((np.argmax(labels, axis=-1) == 0))\n",
        "    different_faces_index = np.where((np.argmax(labels, axis=-1) == 1))\n",
        "\n",
        "    accuracy = np.mean(\n",
        "        (np.argmax(labels[same_faces_index], axis=-1)) ==\n",
        "        (np.argmax(adversarial_labels[same_faces_index], axis=-1))\n",
        "    )\n",
        "    print('Accuracy against adversarial examples for '\n",
        "          + 'same person faces (dodging): '\n",
        "          + str(accuracy * 100)\n",
        "          + '%')\n",
        "\n",
        "    accuracy = np.mean(\n",
        "        (np.argmax(labels[different_faces_index], axis=-1)) == (\n",
        "            np.argmax(adversarial_labels[different_faces_index], axis=-1))\n",
        "    )\n",
        "    print('Accuracy against adversarial examples for '\n",
        "          + 'different people faces (impersonation): '\n",
        "          + str(accuracy * 100)\n",
        "          + '%')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/cleverhans/examples/facenet_adversarial_faces/facenet_fgsm.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42flFaIgHqoR",
        "colab_type": "code",
        "outputId": "20013e23-7b3f-429c-f495-99d382f49ffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%env PYTHONPATH=$PYTHONPATH:/content/facenet/src"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: PYTHONPATH=$PYTHONPATH:/content/facenet/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwC5vtEB1j_W",
        "colab_type": "code",
        "outputId": "b03eeb32-73e2-48e0-f3c1-9ea175c0d66f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd cleverhans/examples/facenet_adversarial_faces/"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/cleverhans/examples/facenet_adversarial_faces\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDGBdhv0Tw06",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b533a209-db31-486e-e1f4-a813a2a4f490"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  datasets\tfacenet_fgsm.py  models  README.md  set_loader.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRBQz7_iUoGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/pairs.txt /content/cleverhans/examples/facenet_adversarial_faces/datasets/lfw/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDb_riq3Z1Rn",
        "colab_type": "code",
        "outputId": "f06f1eca-d50f-4c58-8405-ba80059cf997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        }
      },
      "source": [
        "!cat /content/cleverhans/examples/facenet_adversarial_faces/set_loader.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "import lfw\r\n",
            "import facenet\r\n",
            "\r\n",
            "import numpy as np\r\n",
            "\r\n",
            "\r\n",
            "pairs_path = \"datasets/lfw/pairs.txt\"\r\n",
            "testset_path = \"datasets/lfw/lfw_mtcnnpy_160\"\r\n",
            "file_extension = 'png'\r\n",
            "image_size = 160\r\n",
            "\r\n",
            "\r\n",
            "def load_testset(size):\r\n",
            "  # Load images paths and labels\r\n",
            "  pairs = lfw.read_pairs(pairs_path)\r\n",
            "  paths, labels = lfw.get_paths(testset_path, pairs, file_extension)\r\n",
            "\r\n",
            "  # Random choice\r\n",
            "  permutation = np.random.choice(len(labels), size, replace=False)\r\n",
            "  paths_batch_1 = []\r\n",
            "  paths_batch_2 = []\r\n",
            "\r\n",
            "  for index in permutation:\r\n",
            "    paths_batch_1.append(paths[index * 2])\r\n",
            "    paths_batch_2.append(paths[index * 2 + 1])\r\n",
            "\r\n",
            "  labels = np.asarray(labels)[permutation]\r\n",
            "  paths_batch_1 = np.asarray(paths_batch_1)\r\n",
            "  paths_batch_2 = np.asarray(paths_batch_2)\r\n",
            "\r\n",
            "  # Load images\r\n",
            "  faces1 = facenet.load_data(paths_batch_1, False, False, image_size)\r\n",
            "  faces2 = facenet.load_data(paths_batch_2, False, False, image_size)\r\n",
            "\r\n",
            "  # Change pixel values to 0 to 1 values\r\n",
            "  min_pixel = min(np.min(faces1), np.min(faces2))\r\n",
            "  max_pixel = max(np.max(faces1), np.max(faces2))\r\n",
            "  faces1 = (faces1 - min_pixel) / (max_pixel - min_pixel)\r\n",
            "  faces2 = (faces2 - min_pixel) / (max_pixel - min_pixel)\r\n",
            "\r\n",
            "  # Convert labels to one-hot vectors\r\n",
            "  onehot_labels = []\r\n",
            "  for index in range(len(labels)):\r\n",
            "    if labels[index]:\r\n",
            "      onehot_labels.append([1, 0])\r\n",
            "    else:\r\n",
            "      onehot_labels.append([0, 1])\r\n",
            "\r\n",
            "  return faces1, faces2, np.array(onehot_labels)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_j85_W5TjaHC",
        "colab_type": "code",
        "outputId": "49d507a4-a9c1-425b-9194-8ab180b11c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile /content/cleverhans/examples/facenet_adversarial_faces/set_loader.py\n",
        "import lfw\n",
        "import facenet\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "pairs_path = \"datasets/lfw/pairs.txt\"\n",
        "testset_path = \"datasets/lfw/lfw_mtcnnpy_160\"\n",
        "file_extension = 'png'\n",
        "image_size = 160\n",
        "\n",
        "\n",
        "def load_testset(size):\n",
        "  # Load images paths and labels\n",
        "  pairs = lfw.read_pairs(pairs_path)\n",
        "  #CHANGE HERE\n",
        "  #paths, labels = lfw.get_paths(testset_path, pairs, file_extension)\n",
        "  paths, labels = lfw.get_paths(testset_path, pairs)\n",
        "\n",
        "  # Random choice\n",
        "  permutation = np.random.choice(len(labels), size, replace=False)\n",
        "  paths_batch_1 = []\n",
        "  paths_batch_2 = []\n",
        "\n",
        "  for index in permutation:\n",
        "    paths_batch_1.append(paths[index * 2])\n",
        "    paths_batch_2.append(paths[index * 2 + 1])\n",
        "\n",
        "  labels = np.asarray(labels)[permutation]\n",
        "  paths_batch_1 = np.asarray(paths_batch_1)\n",
        "  paths_batch_2 = np.asarray(paths_batch_2)\n",
        "\n",
        "  # Load images\n",
        "  faces1 = facenet.load_data(paths_batch_1, False, False, image_size)\n",
        "  faces2 = facenet.load_data(paths_batch_2, False, False, image_size)\n",
        "\n",
        "  # Change pixel values to 0 to 1 values\n",
        "  min_pixel = min(np.min(faces1), np.min(faces2))\n",
        "  max_pixel = max(np.max(faces1), np.max(faces2))\n",
        "  faces1 = (faces1 - min_pixel) / (max_pixel - min_pixel)\n",
        "  faces2 = (faces2 - min_pixel) / (max_pixel - min_pixel)\n",
        "\n",
        "  # Convert labels to one-hot vectors\n",
        "  onehot_labels = []\n",
        "  for index in range(len(labels)):\n",
        "    if labels[index]:\n",
        "      onehot_labels.append([1, 0])\n",
        "    else:\n",
        "      onehot_labels.append([0, 1])\n",
        "\n",
        "  return faces1, faces2, np.array(onehot_labels)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/cleverhans/examples/facenet_adversarial_faces/set_loader.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPl0eTnQkfx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib.pyplot import imread"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKUthG4FnMFN",
        "colab_type": "code",
        "outputId": "bbc750ea-76b4-46c1-bc33-c6cf17855ce4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9971
        }
      },
      "source": [
        "!cat /content/facenet/src/facenet.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"\"\"Functions for building the face recognition network.\n",
            "\"\"\"\n",
            "# MIT License\n",
            "# \n",
            "# Copyright (c) 2016 David Sandberg\n",
            "# \n",
            "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
            "# of this software and associated documentation files (the \"Software\"), to deal\n",
            "# in the Software without restriction, including without limitation the rights\n",
            "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
            "# copies of the Software, and to permit persons to whom the Software is\n",
            "# furnished to do so, subject to the following conditions:\n",
            "# \n",
            "# The above copyright notice and this permission notice shall be included in all\n",
            "# copies or substantial portions of the Software.\n",
            "# \n",
            "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
            "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
            "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
            "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
            "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
            "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
            "# SOFTWARE.\n",
            "\n",
            "# pylint: disable=missing-docstring\n",
            "from __future__ import absolute_import\n",
            "from __future__ import division\n",
            "from __future__ import print_function\n",
            "\n",
            "import os\n",
            "from subprocess import Popen, PIPE\n",
            "import tensorflow as tf\n",
            "import numpy as np\n",
            "from scipy import misc\n",
            "from sklearn.model_selection import KFold\n",
            "from scipy import interpolate\n",
            "from tensorflow.python.training import training\n",
            "import random\n",
            "import re\n",
            "from tensorflow.python.platform import gfile\n",
            "import math\n",
            "from six import iteritems\n",
            "\n",
            "def triplet_loss(anchor, positive, negative, alpha):\n",
            "    \"\"\"Calculate the triplet loss according to the FaceNet paper\n",
            "    \n",
            "    Args:\n",
            "      anchor: the embeddings for the anchor images.\n",
            "      positive: the embeddings for the positive images.\n",
            "      negative: the embeddings for the negative images.\n",
            "  \n",
            "    Returns:\n",
            "      the triplet loss according to the FaceNet paper as a float tensor.\n",
            "    \"\"\"\n",
            "    with tf.variable_scope('triplet_loss'):\n",
            "        pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), 1)\n",
            "        neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), 1)\n",
            "        \n",
            "        basic_loss = tf.add(tf.subtract(pos_dist,neg_dist), alpha)\n",
            "        loss = tf.reduce_mean(tf.maximum(basic_loss, 0.0), 0)\n",
            "      \n",
            "    return loss\n",
            "  \n",
            "def center_loss(features, label, alfa, nrof_classes):\n",
            "    \"\"\"Center loss based on the paper \"A Discriminative Feature Learning Approach for Deep Face Recognition\"\n",
            "       (http://ydwen.github.io/papers/WenECCV16.pdf)\n",
            "    \"\"\"\n",
            "    nrof_features = features.get_shape()[1]\n",
            "    centers = tf.get_variable('centers', [nrof_classes, nrof_features], dtype=tf.float32,\n",
            "        initializer=tf.constant_initializer(0), trainable=False)\n",
            "    label = tf.reshape(label, [-1])\n",
            "    centers_batch = tf.gather(centers, label)\n",
            "    diff = (1 - alfa) * (centers_batch - features)\n",
            "    centers = tf.scatter_sub(centers, label, diff)\n",
            "    with tf.control_dependencies([centers]):\n",
            "        loss = tf.reduce_mean(tf.square(features - centers_batch))\n",
            "    return loss, centers\n",
            "\n",
            "def get_image_paths_and_labels(dataset):\n",
            "    image_paths_flat = []\n",
            "    labels_flat = []\n",
            "    for i in range(len(dataset)):\n",
            "        image_paths_flat += dataset[i].image_paths\n",
            "        labels_flat += [i] * len(dataset[i].image_paths)\n",
            "    return image_paths_flat, labels_flat\n",
            "\n",
            "def shuffle_examples(image_paths, labels):\n",
            "    shuffle_list = list(zip(image_paths, labels))\n",
            "    random.shuffle(shuffle_list)\n",
            "    image_paths_shuff, labels_shuff = zip(*shuffle_list)\n",
            "    return image_paths_shuff, labels_shuff\n",
            "\n",
            "def random_rotate_image(image):\n",
            "    angle = np.random.uniform(low=-10.0, high=10.0)\n",
            "    return misc.imrotate(image, angle, 'bicubic')\n",
            "  \n",
            "# 1: Random rotate 2: Random crop  4: Random flip  8:  Fixed image standardization  16: Flip\n",
            "RANDOM_ROTATE = 1\n",
            "RANDOM_CROP = 2\n",
            "RANDOM_FLIP = 4\n",
            "FIXED_STANDARDIZATION = 8\n",
            "FLIP = 16\n",
            "def create_input_pipeline(input_queue, image_size, nrof_preprocess_threads, batch_size_placeholder):\n",
            "  with tf.name_scope(\"tempscope\"):\n",
            "    images_and_labels_list = []\n",
            "    for _ in range(nrof_preprocess_threads):\n",
            "        filenames, label, control = input_queue.dequeue()\n",
            "        images = []\n",
            "        for filename in tf.unstack(filenames):\n",
            "            file_contents = tf.read_file(filename)\n",
            "            image = tf.image.decode_image(file_contents, 3)\n",
            "            image = tf.cond(get_control_flag(control[0], RANDOM_ROTATE),\n",
            "                            lambda:tf.py_func(random_rotate_image, [image], tf.uint8), \n",
            "                            lambda:tf.identity(image))\n",
            "            image = tf.cond(get_control_flag(control[0], RANDOM_CROP), \n",
            "                            lambda:tf.random_crop(image, image_size + (3,)), \n",
            "                            lambda:tf.image.resize_image_with_crop_or_pad(image, image_size[0], image_size[1]))\n",
            "            image = tf.cond(get_control_flag(control[0], RANDOM_FLIP),\n",
            "                            lambda:tf.image.random_flip_left_right(image),\n",
            "                            lambda:tf.identity(image))\n",
            "            image = tf.cond(get_control_flag(control[0], FIXED_STANDARDIZATION),\n",
            "                            lambda:(tf.cast(image, tf.float32) - 127.5)/128.0,\n",
            "                            lambda:tf.image.per_image_standardization(image))\n",
            "            image = tf.cond(get_control_flag(control[0], FLIP),\n",
            "                            lambda:tf.image.flip_left_right(image),\n",
            "                            lambda:tf.identity(image))\n",
            "            #pylint: disable=no-member\n",
            "            image.set_shape(image_size + (3,))\n",
            "            images.append(image)\n",
            "        images_and_labels_list.append([images, label])\n",
            "\n",
            "    image_batch, label_batch = tf.train.batch_join(\n",
            "        images_and_labels_list, batch_size=batch_size_placeholder, \n",
            "        shapes=[image_size + (3,), ()], enqueue_many=True,\n",
            "        capacity=4 * nrof_preprocess_threads * 100,\n",
            "        allow_smaller_final_batch=True)\n",
            "    \n",
            "    return image_batch, label_batch\n",
            "\n",
            "def get_control_flag(control, field):\n",
            "    return tf.equal(tf.mod(tf.floor_div(control, field), 2), 1)\n",
            "  \n",
            "def _add_loss_summaries(total_loss):\n",
            "    \"\"\"Add summaries for losses.\n",
            "  \n",
            "    Generates moving average for all losses and associated summaries for\n",
            "    visualizing the performance of the network.\n",
            "  \n",
            "    Args:\n",
            "      total_loss: Total loss from loss().\n",
            "    Returns:\n",
            "      loss_averages_op: op for generating moving averages of losses.\n",
            "    \"\"\"\n",
            "    # Compute the moving average of all individual losses and the total loss.\n",
            "    loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')\n",
            "    losses = tf.get_collection('losses')\n",
            "    loss_averages_op = loss_averages.apply(losses + [total_loss])\n",
            "  \n",
            "    # Attach a scalar summmary to all individual losses and the total loss; do the\n",
            "    # same for the averaged version of the losses.\n",
            "    for l in losses + [total_loss]:\n",
            "        # Name each loss as '(raw)' and name the moving average version of the loss\n",
            "        # as the original loss name.\n",
            "        tf.summary.scalar(l.op.name +' (raw)', l)\n",
            "        tf.summary.scalar(l.op.name, loss_averages.average(l))\n",
            "  \n",
            "    return loss_averages_op\n",
            "\n",
            "def train(total_loss, global_step, optimizer, learning_rate, moving_average_decay, update_gradient_vars, log_histograms=True):\n",
            "    # Generate moving averages of all losses and associated summaries.\n",
            "    loss_averages_op = _add_loss_summaries(total_loss)\n",
            "\n",
            "    # Compute gradients.\n",
            "    with tf.control_dependencies([loss_averages_op]):\n",
            "        if optimizer=='ADAGRAD':\n",
            "            opt = tf.train.AdagradOptimizer(learning_rate)\n",
            "        elif optimizer=='ADADELTA':\n",
            "            opt = tf.train.AdadeltaOptimizer(learning_rate, rho=0.9, epsilon=1e-6)\n",
            "        elif optimizer=='ADAM':\n",
            "            opt = tf.train.AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999, epsilon=0.1)\n",
            "        elif optimizer=='RMSPROP':\n",
            "            opt = tf.train.RMSPropOptimizer(learning_rate, decay=0.9, momentum=0.9, epsilon=1.0)\n",
            "        elif optimizer=='MOM':\n",
            "            opt = tf.train.MomentumOptimizer(learning_rate, 0.9, use_nesterov=True)\n",
            "        else:\n",
            "            raise ValueError('Invalid optimization algorithm')\n",
            "    \n",
            "        grads = opt.compute_gradients(total_loss, update_gradient_vars)\n",
            "        \n",
            "    # Apply gradients.\n",
            "    apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
            "  \n",
            "    # Add histograms for trainable variables.\n",
            "    if log_histograms:\n",
            "        for var in tf.trainable_variables():\n",
            "            tf.summary.histogram(var.op.name, var)\n",
            "   \n",
            "    # Add histograms for gradients.\n",
            "    if log_histograms:\n",
            "        for grad, var in grads:\n",
            "            if grad is not None:\n",
            "                tf.summary.histogram(var.op.name + '/gradients', grad)\n",
            "  \n",
            "    # Track the moving averages of all trainable variables.\n",
            "    variable_averages = tf.train.ExponentialMovingAverage(\n",
            "        moving_average_decay, global_step)\n",
            "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
            "  \n",
            "    with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n",
            "        train_op = tf.no_op(name='train')\n",
            "  \n",
            "    return train_op\n",
            "\n",
            "def prewhiten(x):\n",
            "    mean = np.mean(x)\n",
            "    std = np.std(x)\n",
            "    std_adj = np.maximum(std, 1.0/np.sqrt(x.size))\n",
            "    y = np.multiply(np.subtract(x, mean), 1/std_adj)\n",
            "    return y  \n",
            "\n",
            "def crop(image, random_crop, image_size):\n",
            "    if image.shape[1]>image_size:\n",
            "        sz1 = int(image.shape[1]//2)\n",
            "        sz2 = int(image_size//2)\n",
            "        if random_crop:\n",
            "            diff = sz1-sz2\n",
            "            (h, v) = (np.random.randint(-diff, diff+1), np.random.randint(-diff, diff+1))\n",
            "        else:\n",
            "            (h, v) = (0,0)\n",
            "        image = image[(sz1-sz2+v):(sz1+sz2+v),(sz1-sz2+h):(sz1+sz2+h),:]\n",
            "    return image\n",
            "  \n",
            "def flip(image, random_flip):\n",
            "    if random_flip and np.random.choice([True, False]):\n",
            "        image = np.fliplr(image)\n",
            "    return image\n",
            "\n",
            "def to_rgb(img):\n",
            "    w, h = img.shape\n",
            "    ret = np.empty((w, h, 3), dtype=np.uint8)\n",
            "    ret[:, :, 0] = ret[:, :, 1] = ret[:, :, 2] = img\n",
            "    return ret\n",
            "  \n",
            "def load_data(image_paths, do_random_crop, do_random_flip, image_size, do_prewhiten=True):\n",
            "    nrof_samples = len(image_paths)\n",
            "    images = np.zeros((nrof_samples, image_size, image_size, 3))\n",
            "    for i in range(nrof_samples):\n",
            "        img = misc.imread(image_paths[i])\n",
            "        if img.ndim == 2:\n",
            "            img = to_rgb(img)\n",
            "        if do_prewhiten:\n",
            "            img = prewhiten(img)\n",
            "        img = crop(img, do_random_crop, image_size)\n",
            "        img = flip(img, do_random_flip)\n",
            "        images[i,:,:,:] = img\n",
            "    return images\n",
            "\n",
            "def get_label_batch(label_data, batch_size, batch_index):\n",
            "    nrof_examples = np.size(label_data, 0)\n",
            "    j = batch_index*batch_size % nrof_examples\n",
            "    if j+batch_size<=nrof_examples:\n",
            "        batch = label_data[j:j+batch_size]\n",
            "    else:\n",
            "        x1 = label_data[j:nrof_examples]\n",
            "        x2 = label_data[0:nrof_examples-j]\n",
            "        batch = np.vstack([x1,x2])\n",
            "    batch_int = batch.astype(np.int64)\n",
            "    return batch_int\n",
            "\n",
            "def get_batch(image_data, batch_size, batch_index):\n",
            "    nrof_examples = np.size(image_data, 0)\n",
            "    j = batch_index*batch_size % nrof_examples\n",
            "    if j+batch_size<=nrof_examples:\n",
            "        batch = image_data[j:j+batch_size,:,:,:]\n",
            "    else:\n",
            "        x1 = image_data[j:nrof_examples,:,:,:]\n",
            "        x2 = image_data[0:nrof_examples-j,:,:,:]\n",
            "        batch = np.vstack([x1,x2])\n",
            "    batch_float = batch.astype(np.float32)\n",
            "    return batch_float\n",
            "\n",
            "def get_triplet_batch(triplets, batch_index, batch_size):\n",
            "    ax, px, nx = triplets\n",
            "    a = get_batch(ax, int(batch_size/3), batch_index)\n",
            "    p = get_batch(px, int(batch_size/3), batch_index)\n",
            "    n = get_batch(nx, int(batch_size/3), batch_index)\n",
            "    batch = np.vstack([a, p, n])\n",
            "    return batch\n",
            "\n",
            "def get_learning_rate_from_file(filename, epoch):\n",
            "    with open(filename, 'r') as f:\n",
            "        for line in f.readlines():\n",
            "            line = line.split('#', 1)[0]\n",
            "            if line:\n",
            "                par = line.strip().split(':')\n",
            "                e = int(par[0])\n",
            "                if par[1]=='-':\n",
            "                    lr = -1\n",
            "                else:\n",
            "                    lr = float(par[1])\n",
            "                if e <= epoch:\n",
            "                    learning_rate = lr\n",
            "                else:\n",
            "                    return learning_rate\n",
            "\n",
            "class ImageClass():\n",
            "    \"Stores the paths to images for a given class\"\n",
            "    def __init__(self, name, image_paths):\n",
            "        self.name = name\n",
            "        self.image_paths = image_paths\n",
            "  \n",
            "    def __str__(self):\n",
            "        return self.name + ', ' + str(len(self.image_paths)) + ' images'\n",
            "  \n",
            "    def __len__(self):\n",
            "        return len(self.image_paths)\n",
            "  \n",
            "def get_dataset(path, has_class_directories=True):\n",
            "    dataset = []\n",
            "    path_exp = os.path.expanduser(path)\n",
            "    classes = [path for path in os.listdir(path_exp) \\\n",
            "                    if os.path.isdir(os.path.join(path_exp, path))]\n",
            "    classes.sort()\n",
            "    nrof_classes = len(classes)\n",
            "    for i in range(nrof_classes):\n",
            "        class_name = classes[i]\n",
            "        facedir = os.path.join(path_exp, class_name)\n",
            "        image_paths = get_image_paths(facedir)\n",
            "        dataset.append(ImageClass(class_name, image_paths))\n",
            "  \n",
            "    return dataset\n",
            "\n",
            "def get_image_paths(facedir):\n",
            "    image_paths = []\n",
            "    if os.path.isdir(facedir):\n",
            "        images = os.listdir(facedir)\n",
            "        image_paths = [os.path.join(facedir,img) for img in images]\n",
            "    return image_paths\n",
            "  \n",
            "def split_dataset(dataset, split_ratio, min_nrof_images_per_class, mode):\n",
            "    if mode=='SPLIT_CLASSES':\n",
            "        nrof_classes = len(dataset)\n",
            "        class_indices = np.arange(nrof_classes)\n",
            "        np.random.shuffle(class_indices)\n",
            "        split = int(round(nrof_classes*(1-split_ratio)))\n",
            "        train_set = [dataset[i] for i in class_indices[0:split]]\n",
            "        test_set = [dataset[i] for i in class_indices[split:-1]]\n",
            "    elif mode=='SPLIT_IMAGES':\n",
            "        train_set = []\n",
            "        test_set = []\n",
            "        for cls in dataset:\n",
            "            paths = cls.image_paths\n",
            "            np.random.shuffle(paths)\n",
            "            nrof_images_in_class = len(paths)\n",
            "            split = int(math.floor(nrof_images_in_class*(1-split_ratio)))\n",
            "            if split==nrof_images_in_class:\n",
            "                split = nrof_images_in_class-1\n",
            "            if split>=min_nrof_images_per_class and nrof_images_in_class-split>=1:\n",
            "                train_set.append(ImageClass(cls.name, paths[:split]))\n",
            "                test_set.append(ImageClass(cls.name, paths[split:]))\n",
            "    else:\n",
            "        raise ValueError('Invalid train/test split mode \"%s\"' % mode)\n",
            "    return train_set, test_set\n",
            "\n",
            "def load_model(model, input_map=None):\n",
            "    # Check if the model is a model directory (containing a metagraph and a checkpoint file)\n",
            "    #  or if it is a protobuf file with a frozen graph\n",
            "    model_exp = os.path.expanduser(model)\n",
            "    if (os.path.isfile(model_exp)):\n",
            "        print('Model filename: %s' % model_exp)\n",
            "        with gfile.FastGFile(model_exp,'rb') as f:\n",
            "            graph_def = tf.GraphDef()\n",
            "            graph_def.ParseFromString(f.read())\n",
            "            tf.import_graph_def(graph_def, input_map=input_map, name='')\n",
            "    else:\n",
            "        print('Model directory: %s' % model_exp)\n",
            "        meta_file, ckpt_file = get_model_filenames(model_exp)\n",
            "        \n",
            "        print('Metagraph file: %s' % meta_file)\n",
            "        print('Checkpoint file: %s' % ckpt_file)\n",
            "      \n",
            "        saver = tf.train.import_meta_graph(os.path.join(model_exp, meta_file), input_map=input_map)\n",
            "        saver.restore(tf.get_default_session(), os.path.join(model_exp, ckpt_file))\n",
            "    \n",
            "def get_model_filenames(model_dir):\n",
            "    files = os.listdir(model_dir)\n",
            "    meta_files = [s for s in files if s.endswith('.meta')]\n",
            "    if len(meta_files)==0:\n",
            "        raise ValueError('No meta file found in the model directory (%s)' % model_dir)\n",
            "    elif len(meta_files)>1:\n",
            "        raise ValueError('There should not be more than one meta file in the model directory (%s)' % model_dir)\n",
            "    meta_file = meta_files[0]\n",
            "    ckpt = tf.train.get_checkpoint_state(model_dir)\n",
            "    if ckpt and ckpt.model_checkpoint_path:\n",
            "        ckpt_file = os.path.basename(ckpt.model_checkpoint_path)\n",
            "        return meta_file, ckpt_file\n",
            "\n",
            "    meta_files = [s for s in files if '.ckpt' in s]\n",
            "    max_step = -1\n",
            "    for f in files:\n",
            "        step_str = re.match(r'(^model-[\\w\\- ]+.ckpt-(\\d+))', f)\n",
            "        if step_str is not None and len(step_str.groups())>=2:\n",
            "            step = int(step_str.groups()[1])\n",
            "            if step > max_step:\n",
            "                max_step = step\n",
            "                ckpt_file = step_str.groups()[0]\n",
            "    return meta_file, ckpt_file\n",
            "  \n",
            "def distance(embeddings1, embeddings2, distance_metric=0):\n",
            "    if distance_metric==0:\n",
            "        # Euclidian distance\n",
            "        diff = np.subtract(embeddings1, embeddings2)\n",
            "        dist = np.sum(np.square(diff),1)\n",
            "    elif distance_metric==1:\n",
            "        # Distance based on cosine similarity\n",
            "        dot = np.sum(np.multiply(embeddings1, embeddings2), axis=1)\n",
            "        norm = np.linalg.norm(embeddings1, axis=1) * np.linalg.norm(embeddings2, axis=1)\n",
            "        similarity = dot / norm\n",
            "        dist = np.arccos(similarity) / math.pi\n",
            "    else:\n",
            "        raise 'Undefined distance metric %d' % distance_metric \n",
            "        \n",
            "    return dist\n",
            "\n",
            "def calculate_roc(thresholds, embeddings1, embeddings2, actual_issame, nrof_folds=10, distance_metric=0, subtract_mean=False):\n",
            "    assert(embeddings1.shape[0] == embeddings2.shape[0])\n",
            "    assert(embeddings1.shape[1] == embeddings2.shape[1])\n",
            "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
            "    nrof_thresholds = len(thresholds)\n",
            "    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n",
            "    \n",
            "    tprs = np.zeros((nrof_folds,nrof_thresholds))\n",
            "    fprs = np.zeros((nrof_folds,nrof_thresholds))\n",
            "    accuracy = np.zeros((nrof_folds))\n",
            "    \n",
            "    indices = np.arange(nrof_pairs)\n",
            "    \n",
            "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
            "        if subtract_mean:\n",
            "            mean = np.mean(np.concatenate([embeddings1[train_set], embeddings2[train_set]]), axis=0)\n",
            "        else:\n",
            "          mean = 0.0\n",
            "        dist = distance(embeddings1-mean, embeddings2-mean, distance_metric)\n",
            "        \n",
            "        # Find the best threshold for the fold\n",
            "        acc_train = np.zeros((nrof_thresholds))\n",
            "        for threshold_idx, threshold in enumerate(thresholds):\n",
            "            _, _, acc_train[threshold_idx] = calculate_accuracy(threshold, dist[train_set], actual_issame[train_set])\n",
            "        best_threshold_index = np.argmax(acc_train)\n",
            "        for threshold_idx, threshold in enumerate(thresholds):\n",
            "            tprs[fold_idx,threshold_idx], fprs[fold_idx,threshold_idx], _ = calculate_accuracy(threshold, dist[test_set], actual_issame[test_set])\n",
            "        _, _, accuracy[fold_idx] = calculate_accuracy(thresholds[best_threshold_index], dist[test_set], actual_issame[test_set])\n",
            "          \n",
            "        tpr = np.mean(tprs,0)\n",
            "        fpr = np.mean(fprs,0)\n",
            "    return tpr, fpr, accuracy\n",
            "\n",
            "def calculate_accuracy(threshold, dist, actual_issame):\n",
            "    predict_issame = np.less(dist, threshold)\n",
            "    tp = np.sum(np.logical_and(predict_issame, actual_issame))\n",
            "    fp = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n",
            "    tn = np.sum(np.logical_and(np.logical_not(predict_issame), np.logical_not(actual_issame)))\n",
            "    fn = np.sum(np.logical_and(np.logical_not(predict_issame), actual_issame))\n",
            "  \n",
            "    tpr = 0 if (tp+fn==0) else float(tp) / float(tp+fn)\n",
            "    fpr = 0 if (fp+tn==0) else float(fp) / float(fp+tn)\n",
            "    acc = float(tp+tn)/dist.size\n",
            "    return tpr, fpr, acc\n",
            "\n",
            "\n",
            "  \n",
            "def calculate_val(thresholds, embeddings1, embeddings2, actual_issame, far_target, nrof_folds=10, distance_metric=0, subtract_mean=False):\n",
            "    assert(embeddings1.shape[0] == embeddings2.shape[0])\n",
            "    assert(embeddings1.shape[1] == embeddings2.shape[1])\n",
            "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
            "    nrof_thresholds = len(thresholds)\n",
            "    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n",
            "    \n",
            "    val = np.zeros(nrof_folds)\n",
            "    far = np.zeros(nrof_folds)\n",
            "    \n",
            "    indices = np.arange(nrof_pairs)\n",
            "    \n",
            "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
            "        if subtract_mean:\n",
            "            mean = np.mean(np.concatenate([embeddings1[train_set], embeddings2[train_set]]), axis=0)\n",
            "        else:\n",
            "          mean = 0.0\n",
            "        dist = distance(embeddings1-mean, embeddings2-mean, distance_metric)\n",
            "      \n",
            "        # Find the threshold that gives FAR = far_target\n",
            "        far_train = np.zeros(nrof_thresholds)\n",
            "        for threshold_idx, threshold in enumerate(thresholds):\n",
            "            _, far_train[threshold_idx] = calculate_val_far(threshold, dist[train_set], actual_issame[train_set])\n",
            "        if np.max(far_train)>=far_target:\n",
            "            f = interpolate.interp1d(far_train, thresholds, kind='slinear')\n",
            "            threshold = f(far_target)\n",
            "        else:\n",
            "            threshold = 0.0\n",
            "    \n",
            "        val[fold_idx], far[fold_idx] = calculate_val_far(threshold, dist[test_set], actual_issame[test_set])\n",
            "  \n",
            "    val_mean = np.mean(val)\n",
            "    far_mean = np.mean(far)\n",
            "    val_std = np.std(val)\n",
            "    return val_mean, val_std, far_mean\n",
            "\n",
            "\n",
            "def calculate_val_far(threshold, dist, actual_issame):\n",
            "    predict_issame = np.less(dist, threshold)\n",
            "    true_accept = np.sum(np.logical_and(predict_issame, actual_issame))\n",
            "    false_accept = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n",
            "    n_same = np.sum(actual_issame)\n",
            "    n_diff = np.sum(np.logical_not(actual_issame))\n",
            "    val = float(true_accept) / float(n_same)\n",
            "    far = float(false_accept) / float(n_diff)\n",
            "    return val, far\n",
            "\n",
            "def store_revision_info(src_path, output_dir, arg_string):\n",
            "    try:\n",
            "        # Get git hash\n",
            "        cmd = ['git', 'rev-parse', 'HEAD']\n",
            "        gitproc = Popen(cmd, stdout = PIPE, cwd=src_path)\n",
            "        (stdout, _) = gitproc.communicate()\n",
            "        git_hash = stdout.strip()\n",
            "    except OSError as e:\n",
            "        git_hash = ' '.join(cmd) + ': ' +  e.strerror\n",
            "  \n",
            "    try:\n",
            "        # Get local changes\n",
            "        cmd = ['git', 'diff', 'HEAD']\n",
            "        gitproc = Popen(cmd, stdout = PIPE, cwd=src_path)\n",
            "        (stdout, _) = gitproc.communicate()\n",
            "        git_diff = stdout.strip()\n",
            "    except OSError as e:\n",
            "        git_diff = ' '.join(cmd) + ': ' +  e.strerror\n",
            "    \n",
            "    # Store a text file in the log directory\n",
            "    rev_info_filename = os.path.join(output_dir, 'revision_info.txt')\n",
            "    with open(rev_info_filename, \"w\") as text_file:\n",
            "        text_file.write('arguments: %s\\n--------------------\\n' % arg_string)\n",
            "        text_file.write('tensorflow version: %s\\n--------------------\\n' % tf.__version__)  # @UndefinedVariable\n",
            "        text_file.write('git hash: %s\\n--------------------\\n' % git_hash)\n",
            "        text_file.write('%s' % git_diff)\n",
            "\n",
            "def list_variables(filename):\n",
            "    reader = training.NewCheckpointReader(filename)\n",
            "    variable_map = reader.get_variable_to_shape_map()\n",
            "    names = sorted(variable_map.keys())\n",
            "    return names\n",
            "\n",
            "def put_images_on_grid(images, shape=(16,8)):\n",
            "    nrof_images = images.shape[0]\n",
            "    img_size = images.shape[1]\n",
            "    bw = 3\n",
            "    img = np.zeros((shape[1]*(img_size+bw)+bw, shape[0]*(img_size+bw)+bw, 3), np.float32)\n",
            "    for i in range(shape[1]):\n",
            "        x_start = i*(img_size+bw)+bw\n",
            "        for j in range(shape[0]):\n",
            "            img_index = i*shape[0]+j\n",
            "            if img_index>=nrof_images:\n",
            "                break\n",
            "            y_start = j*(img_size+bw)+bw\n",
            "            img[x_start:x_start+img_size, y_start:y_start+img_size, :] = images[img_index, :, :, :]\n",
            "        if img_index>=nrof_images:\n",
            "            break\n",
            "    return img\n",
            "\n",
            "def write_arguments_to_file(args, filename):\n",
            "    with open(filename, 'w') as f:\n",
            "        for key, value in iteritems(vars(args)):\n",
            "            f.write('%s: %s\\n' % (key, str(value)))"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUKnxh1GnMWG",
        "colab_type": "code",
        "outputId": "3486d263-64da-4306-e835-a6a291b04234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile /content/facenet/src/facenet.py\n",
        "\"\"\"Functions for building the face recognition network.\n",
        "\"\"\"\n",
        "# MIT License\n",
        "# \n",
        "# Copyright (c) 2016 David Sandberg\n",
        "# \n",
        "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "# of this software and associated documentation files (the \"Software\"), to deal\n",
        "# in the Software without restriction, including without limitation the rights\n",
        "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "# copies of the Software, and to permit persons to whom the Software is\n",
        "# furnished to do so, subject to the following conditions:\n",
        "# \n",
        "# The above copyright notice and this permission notice shall be included in all\n",
        "# copies or substantial portions of the Software.\n",
        "# \n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "# SOFTWARE.\n",
        "\n",
        "# pylint: disable=missing-docstring\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "#CHANGE HERE\n",
        "import imageio\n",
        "\n",
        "import os\n",
        "from subprocess import Popen, PIPE\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from scipy import misc\n",
        "from sklearn.model_selection import KFold\n",
        "from scipy import interpolate\n",
        "from tensorflow.python.training import training\n",
        "import random\n",
        "import re\n",
        "from tensorflow.python.platform import gfile\n",
        "import math\n",
        "from six import iteritems\n",
        "\n",
        "def triplet_loss(anchor, positive, negative, alpha):\n",
        "    \"\"\"Calculate the triplet loss according to the FaceNet paper\n",
        "    \n",
        "    Args:\n",
        "      anchor: the embeddings for the anchor images.\n",
        "      positive: the embeddings for the positive images.\n",
        "      negative: the embeddings for the negative images.\n",
        "  \n",
        "    Returns:\n",
        "      the triplet loss according to the FaceNet paper as a float tensor.\n",
        "    \"\"\"\n",
        "    with tf.variable_scope('triplet_loss'):\n",
        "        pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), 1)\n",
        "        neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), 1)\n",
        "        \n",
        "        basic_loss = tf.add(tf.subtract(pos_dist,neg_dist), alpha)\n",
        "        loss = tf.reduce_mean(tf.maximum(basic_loss, 0.0), 0)\n",
        "      \n",
        "    return loss\n",
        "  \n",
        "def center_loss(features, label, alfa, nrof_classes):\n",
        "    \"\"\"Center loss based on the paper \"A Discriminative Feature Learning Approach for Deep Face Recognition\"\n",
        "       (http://ydwen.github.io/papers/WenECCV16.pdf)\n",
        "    \"\"\"\n",
        "    nrof_features = features.get_shape()[1]\n",
        "    centers = tf.get_variable('centers', [nrof_classes, nrof_features], dtype=tf.float32,\n",
        "        initializer=tf.constant_initializer(0), trainable=False)\n",
        "    label = tf.reshape(label, [-1])\n",
        "    centers_batch = tf.gather(centers, label)\n",
        "    diff = (1 - alfa) * (centers_batch - features)\n",
        "    centers = tf.scatter_sub(centers, label, diff)\n",
        "    with tf.control_dependencies([centers]):\n",
        "        loss = tf.reduce_mean(tf.square(features - centers_batch))\n",
        "    return loss, centers\n",
        "\n",
        "def get_image_paths_and_labels(dataset):\n",
        "    image_paths_flat = []\n",
        "    labels_flat = []\n",
        "    for i in range(len(dataset)):\n",
        "        image_paths_flat += dataset[i].image_paths\n",
        "        labels_flat += [i] * len(dataset[i].image_paths)\n",
        "    return image_paths_flat, labels_flat\n",
        "\n",
        "def shuffle_examples(image_paths, labels):\n",
        "    shuffle_list = list(zip(image_paths, labels))\n",
        "    random.shuffle(shuffle_list)\n",
        "    image_paths_shuff, labels_shuff = zip(*shuffle_list)\n",
        "    return image_paths_shuff, labels_shuff\n",
        "\n",
        "def random_rotate_image(image):\n",
        "    angle = np.random.uniform(low=-10.0, high=10.0)\n",
        "    return misc.imrotate(image, angle, 'bicubic')\n",
        "  \n",
        "# 1: Random rotate 2: Random crop  4: Random flip  8:  Fixed image standardization  16: Flip\n",
        "RANDOM_ROTATE = 1\n",
        "RANDOM_CROP = 2\n",
        "RANDOM_FLIP = 4\n",
        "FIXED_STANDARDIZATION = 8\n",
        "FLIP = 16\n",
        "def create_input_pipeline(input_queue, image_size, nrof_preprocess_threads, batch_size_placeholder):\n",
        "  with tf.name_scope(\"tempscope\"):\n",
        "    images_and_labels_list = []\n",
        "    for _ in range(nrof_preprocess_threads):\n",
        "        filenames, label, control = input_queue.dequeue()\n",
        "        images = []\n",
        "        for filename in tf.unstack(filenames):\n",
        "            file_contents = tf.read_file(filename)\n",
        "            image = tf.image.decode_image(file_contents, 3)\n",
        "            image = tf.cond(get_control_flag(control[0], RANDOM_ROTATE),\n",
        "                            lambda:tf.py_func(random_rotate_image, [image], tf.uint8), \n",
        "                            lambda:tf.identity(image))\n",
        "            image = tf.cond(get_control_flag(control[0], RANDOM_CROP), \n",
        "                            lambda:tf.random_crop(image, image_size + (3,)), \n",
        "                            lambda:tf.image.resize_image_with_crop_or_pad(image, image_size[0], image_size[1]))\n",
        "            image = tf.cond(get_control_flag(control[0], RANDOM_FLIP),\n",
        "                            lambda:tf.image.random_flip_left_right(image),\n",
        "                            lambda:tf.identity(image))\n",
        "            image = tf.cond(get_control_flag(control[0], FIXED_STANDARDIZATION),\n",
        "                            lambda:(tf.cast(image, tf.float32) - 127.5)/128.0,\n",
        "                            lambda:tf.image.per_image_standardization(image))\n",
        "            image = tf.cond(get_control_flag(control[0], FLIP),\n",
        "                            lambda:tf.image.flip_left_right(image),\n",
        "                            lambda:tf.identity(image))\n",
        "            #pylint: disable=no-member\n",
        "            image.set_shape(image_size + (3,))\n",
        "            images.append(image)\n",
        "        images_and_labels_list.append([images, label])\n",
        "\n",
        "    image_batch, label_batch = tf.train.batch_join(\n",
        "        images_and_labels_list, batch_size=batch_size_placeholder, \n",
        "        shapes=[image_size + (3,), ()], enqueue_many=True,\n",
        "        capacity=4 * nrof_preprocess_threads * 100,\n",
        "        allow_smaller_final_batch=True)\n",
        "    \n",
        "    return image_batch, label_batch\n",
        "\n",
        "def get_control_flag(control, field):\n",
        "    return tf.equal(tf.mod(tf.floor_div(control, field), 2), 1)\n",
        "  \n",
        "def _add_loss_summaries(total_loss):\n",
        "    \"\"\"Add summaries for losses.\n",
        "  \n",
        "    Generates moving average for all losses and associated summaries for\n",
        "    visualizing the performance of the network.\n",
        "  \n",
        "    Args:\n",
        "      total_loss: Total loss from loss().\n",
        "    Returns:\n",
        "      loss_averages_op: op for generating moving averages of losses.\n",
        "    \"\"\"\n",
        "    # Compute the moving average of all individual losses and the total loss.\n",
        "    loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')\n",
        "    losses = tf.get_collection('losses')\n",
        "    loss_averages_op = loss_averages.apply(losses + [total_loss])\n",
        "  \n",
        "    # Attach a scalar summmary to all individual losses and the total loss; do the\n",
        "    # same for the averaged version of the losses.\n",
        "    for l in losses + [total_loss]:\n",
        "        # Name each loss as '(raw)' and name the moving average version of the loss\n",
        "        # as the original loss name.\n",
        "        tf.summary.scalar(l.op.name +' (raw)', l)\n",
        "        tf.summary.scalar(l.op.name, loss_averages.average(l))\n",
        "  \n",
        "    return loss_averages_op\n",
        "\n",
        "def train(total_loss, global_step, optimizer, learning_rate, moving_average_decay, update_gradient_vars, log_histograms=True):\n",
        "    # Generate moving averages of all losses and associated summaries.\n",
        "    loss_averages_op = _add_loss_summaries(total_loss)\n",
        "\n",
        "    # Compute gradients.\n",
        "    with tf.control_dependencies([loss_averages_op]):\n",
        "        if optimizer=='ADAGRAD':\n",
        "            opt = tf.train.AdagradOptimizer(learning_rate)\n",
        "        elif optimizer=='ADADELTA':\n",
        "            opt = tf.train.AdadeltaOptimizer(learning_rate, rho=0.9, epsilon=1e-6)\n",
        "        elif optimizer=='ADAM':\n",
        "            opt = tf.train.AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999, epsilon=0.1)\n",
        "        elif optimizer=='RMSPROP':\n",
        "            opt = tf.train.RMSPropOptimizer(learning_rate, decay=0.9, momentum=0.9, epsilon=1.0)\n",
        "        elif optimizer=='MOM':\n",
        "            opt = tf.train.MomentumOptimizer(learning_rate, 0.9, use_nesterov=True)\n",
        "        else:\n",
        "            raise ValueError('Invalid optimization algorithm')\n",
        "    \n",
        "        grads = opt.compute_gradients(total_loss, update_gradient_vars)\n",
        "        \n",
        "    # Apply gradients.\n",
        "    apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
        "  \n",
        "    # Add histograms for trainable variables.\n",
        "    if log_histograms:\n",
        "        for var in tf.trainable_variables():\n",
        "            tf.summary.histogram(var.op.name, var)\n",
        "   \n",
        "    # Add histograms for gradients.\n",
        "    if log_histograms:\n",
        "        for grad, var in grads:\n",
        "            if grad is not None:\n",
        "                tf.summary.histogram(var.op.name + '/gradients', grad)\n",
        "  \n",
        "    # Track the moving averages of all trainable variables.\n",
        "    variable_averages = tf.train.ExponentialMovingAverage(\n",
        "        moving_average_decay, global_step)\n",
        "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
        "  \n",
        "    with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n",
        "        train_op = tf.no_op(name='train')\n",
        "  \n",
        "    return train_op\n",
        "\n",
        "def prewhiten(x):\n",
        "    mean = np.mean(x)\n",
        "    std = np.std(x)\n",
        "    std_adj = np.maximum(std, 1.0/np.sqrt(x.size))\n",
        "    y = np.multiply(np.subtract(x, mean), 1/std_adj)\n",
        "    return y  \n",
        "\n",
        "def crop(image, random_crop, image_size):\n",
        "    if image.shape[1]>image_size:\n",
        "        sz1 = int(image.shape[1]//2)\n",
        "        sz2 = int(image_size//2)\n",
        "        if random_crop:\n",
        "            diff = sz1-sz2\n",
        "            (h, v) = (np.random.randint(-diff, diff+1), np.random.randint(-diff, diff+1))\n",
        "        else:\n",
        "            (h, v) = (0,0)\n",
        "        image = image[(sz1-sz2+v):(sz1+sz2+v),(sz1-sz2+h):(sz1+sz2+h),:]\n",
        "    return image\n",
        "  \n",
        "def flip(image, random_flip):\n",
        "    if random_flip and np.random.choice([True, False]):\n",
        "        image = np.fliplr(image)\n",
        "    return image\n",
        "\n",
        "def to_rgb(img):\n",
        "    w, h = img.shape\n",
        "    ret = np.empty((w, h, 3), dtype=np.uint8)\n",
        "    ret[:, :, 0] = ret[:, :, 1] = ret[:, :, 2] = img\n",
        "    return ret\n",
        "  \n",
        "def load_data(image_paths, do_random_crop, do_random_flip, image_size, do_prewhiten=True):\n",
        "    nrof_samples = len(image_paths)\n",
        "    images = np.zeros((nrof_samples, image_size, image_size, 3))\n",
        "    for i in range(nrof_samples):\n",
        "        #CHANGE HERE\n",
        "        #img = misc.imread(image_paths[i])\n",
        "        img = imageio.imread(image_paths[i])\n",
        "        if img.ndim == 2:\n",
        "            img = to_rgb(img)\n",
        "        if do_prewhiten:\n",
        "            img = prewhiten(img)\n",
        "        img = crop(img, do_random_crop, image_size)\n",
        "        img = flip(img, do_random_flip)\n",
        "        images[i,:,:,:] = img\n",
        "    return images\n",
        "\n",
        "def get_label_batch(label_data, batch_size, batch_index):\n",
        "    nrof_examples = np.size(label_data, 0)\n",
        "    j = batch_index*batch_size % nrof_examples\n",
        "    if j+batch_size<=nrof_examples:\n",
        "        batch = label_data[j:j+batch_size]\n",
        "    else:\n",
        "        x1 = label_data[j:nrof_examples]\n",
        "        x2 = label_data[0:nrof_examples-j]\n",
        "        batch = np.vstack([x1,x2])\n",
        "    batch_int = batch.astype(np.int64)\n",
        "    return batch_int\n",
        "\n",
        "def get_batch(image_data, batch_size, batch_index):\n",
        "    nrof_examples = np.size(image_data, 0)\n",
        "    j = batch_index*batch_size % nrof_examples\n",
        "    if j+batch_size<=nrof_examples:\n",
        "        batch = image_data[j:j+batch_size,:,:,:]\n",
        "    else:\n",
        "        x1 = image_data[j:nrof_examples,:,:,:]\n",
        "        x2 = image_data[0:nrof_examples-j,:,:,:]\n",
        "        batch = np.vstack([x1,x2])\n",
        "    batch_float = batch.astype(np.float32)\n",
        "    return batch_float\n",
        "\n",
        "def get_triplet_batch(triplets, batch_index, batch_size):\n",
        "    ax, px, nx = triplets\n",
        "    a = get_batch(ax, int(batch_size/3), batch_index)\n",
        "    p = get_batch(px, int(batch_size/3), batch_index)\n",
        "    n = get_batch(nx, int(batch_size/3), batch_index)\n",
        "    batch = np.vstack([a, p, n])\n",
        "    return batch\n",
        "\n",
        "def get_learning_rate_from_file(filename, epoch):\n",
        "    with open(filename, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.split('#', 1)[0]\n",
        "            if line:\n",
        "                par = line.strip().split(':')\n",
        "                e = int(par[0])\n",
        "                if par[1]=='-':\n",
        "                    lr = -1\n",
        "                else:\n",
        "                    lr = float(par[1])\n",
        "                if e <= epoch:\n",
        "                    learning_rate = lr\n",
        "                else:\n",
        "                    return learning_rate\n",
        "\n",
        "class ImageClass():\n",
        "    \"Stores the paths to images for a given class\"\n",
        "    def __init__(self, name, image_paths):\n",
        "        self.name = name\n",
        "        self.image_paths = image_paths\n",
        "  \n",
        "    def __str__(self):\n",
        "        return self.name + ', ' + str(len(self.image_paths)) + ' images'\n",
        "  \n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "  \n",
        "def get_dataset(path, has_class_directories=True):\n",
        "    dataset = []\n",
        "    path_exp = os.path.expanduser(path)\n",
        "    classes = [path for path in os.listdir(path_exp) \\\n",
        "                    if os.path.isdir(os.path.join(path_exp, path))]\n",
        "    classes.sort()\n",
        "    nrof_classes = len(classes)\n",
        "    for i in range(nrof_classes):\n",
        "        class_name = classes[i]\n",
        "        facedir = os.path.join(path_exp, class_name)\n",
        "        image_paths = get_image_paths(facedir)\n",
        "        dataset.append(ImageClass(class_name, image_paths))\n",
        "  \n",
        "    return dataset\n",
        "\n",
        "def get_image_paths(facedir):\n",
        "    image_paths = []\n",
        "    if os.path.isdir(facedir):\n",
        "        images = os.listdir(facedir)\n",
        "        image_paths = [os.path.join(facedir,img) for img in images]\n",
        "    return image_paths\n",
        "  \n",
        "def split_dataset(dataset, split_ratio, min_nrof_images_per_class, mode):\n",
        "    if mode=='SPLIT_CLASSES':\n",
        "        nrof_classes = len(dataset)\n",
        "        class_indices = np.arange(nrof_classes)\n",
        "        np.random.shuffle(class_indices)\n",
        "        split = int(round(nrof_classes*(1-split_ratio)))\n",
        "        train_set = [dataset[i] for i in class_indices[0:split]]\n",
        "        test_set = [dataset[i] for i in class_indices[split:-1]]\n",
        "    elif mode=='SPLIT_IMAGES':\n",
        "        train_set = []\n",
        "        test_set = []\n",
        "        for cls in dataset:\n",
        "            paths = cls.image_paths\n",
        "            np.random.shuffle(paths)\n",
        "            nrof_images_in_class = len(paths)\n",
        "            split = int(math.floor(nrof_images_in_class*(1-split_ratio)))\n",
        "            if split==nrof_images_in_class:\n",
        "                split = nrof_images_in_class-1\n",
        "            if split>=min_nrof_images_per_class and nrof_images_in_class-split>=1:\n",
        "                train_set.append(ImageClass(cls.name, paths[:split]))\n",
        "                test_set.append(ImageClass(cls.name, paths[split:]))\n",
        "    else:\n",
        "        raise ValueError('Invalid train/test split mode \"%s\"' % mode)\n",
        "    return train_set, test_set\n",
        "\n",
        "def load_model(model, input_map=None):\n",
        "    # Check if the model is a model directory (containing a metagraph and a checkpoint file)\n",
        "    #  or if it is a protobuf file with a frozen graph\n",
        "    model_exp = os.path.expanduser(model)\n",
        "    if (os.path.isfile(model_exp)):\n",
        "        print('Model filename: %s' % model_exp)\n",
        "        with gfile.FastGFile(model_exp,'rb') as f:\n",
        "            graph_def = tf.GraphDef()\n",
        "            graph_def.ParseFromString(f.read())\n",
        "            tf.import_graph_def(graph_def, input_map=input_map, name='')\n",
        "    else:\n",
        "        print('Model directory: %s' % model_exp)\n",
        "        meta_file, ckpt_file = get_model_filenames(model_exp)\n",
        "        \n",
        "        print('Metagraph file: %s' % meta_file)\n",
        "        print('Checkpoint file: %s' % ckpt_file)\n",
        "      \n",
        "        saver = tf.train.import_meta_graph(os.path.join(model_exp, meta_file), input_map=input_map)\n",
        "        saver.restore(tf.get_default_session(), os.path.join(model_exp, ckpt_file))\n",
        "    \n",
        "def get_model_filenames(model_dir):\n",
        "    files = os.listdir(model_dir)\n",
        "    meta_files = [s for s in files if s.endswith('.meta')]\n",
        "    if len(meta_files)==0:\n",
        "        raise ValueError('No meta file found in the model directory (%s)' % model_dir)\n",
        "    elif len(meta_files)>1:\n",
        "        raise ValueError('There should not be more than one meta file in the model directory (%s)' % model_dir)\n",
        "    meta_file = meta_files[0]\n",
        "    ckpt = tf.train.get_checkpoint_state(model_dir)\n",
        "    if ckpt and ckpt.model_checkpoint_path:\n",
        "        ckpt_file = os.path.basename(ckpt.model_checkpoint_path)\n",
        "        return meta_file, ckpt_file\n",
        "\n",
        "    meta_files = [s for s in files if '.ckpt' in s]\n",
        "    max_step = -1\n",
        "    for f in files:\n",
        "        step_str = re.match(r'(^model-[\\w\\- ]+.ckpt-(\\d+))', f)\n",
        "        if step_str is not None and len(step_str.groups())>=2:\n",
        "            step = int(step_str.groups()[1])\n",
        "            if step > max_step:\n",
        "                max_step = step\n",
        "                ckpt_file = step_str.groups()[0]\n",
        "    return meta_file, ckpt_file\n",
        "  \n",
        "def distance(embeddings1, embeddings2, distance_metric=0):\n",
        "    if distance_metric==0:\n",
        "        # Euclidian distance\n",
        "        diff = np.subtract(embeddings1, embeddings2)\n",
        "        dist = np.sum(np.square(diff),1)\n",
        "    elif distance_metric==1:\n",
        "        # Distance based on cosine similarity\n",
        "        dot = np.sum(np.multiply(embeddings1, embeddings2), axis=1)\n",
        "        norm = np.linalg.norm(embeddings1, axis=1) * np.linalg.norm(embeddings2, axis=1)\n",
        "        similarity = dot / norm\n",
        "        dist = np.arccos(similarity) / math.pi\n",
        "    else:\n",
        "        raise 'Undefined distance metric %d' % distance_metric \n",
        "        \n",
        "    return dist\n",
        "\n",
        "def calculate_roc(thresholds, embeddings1, embeddings2, actual_issame, nrof_folds=10, distance_metric=0, subtract_mean=False):\n",
        "    assert(embeddings1.shape[0] == embeddings2.shape[0])\n",
        "    assert(embeddings1.shape[1] == embeddings2.shape[1])\n",
        "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
        "    nrof_thresholds = len(thresholds)\n",
        "    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n",
        "    \n",
        "    tprs = np.zeros((nrof_folds,nrof_thresholds))\n",
        "    fprs = np.zeros((nrof_folds,nrof_thresholds))\n",
        "    accuracy = np.zeros((nrof_folds))\n",
        "    \n",
        "    indices = np.arange(nrof_pairs)\n",
        "    \n",
        "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
        "        if subtract_mean:\n",
        "            mean = np.mean(np.concatenate([embeddings1[train_set], embeddings2[train_set]]), axis=0)\n",
        "        else:\n",
        "          mean = 0.0\n",
        "        dist = distance(embeddings1-mean, embeddings2-mean, distance_metric)\n",
        "        \n",
        "        # Find the best threshold for the fold\n",
        "        acc_train = np.zeros((nrof_thresholds))\n",
        "        for threshold_idx, threshold in enumerate(thresholds):\n",
        "            _, _, acc_train[threshold_idx] = calculate_accuracy(threshold, dist[train_set], actual_issame[train_set])\n",
        "        best_threshold_index = np.argmax(acc_train)\n",
        "        for threshold_idx, threshold in enumerate(thresholds):\n",
        "            tprs[fold_idx,threshold_idx], fprs[fold_idx,threshold_idx], _ = calculate_accuracy(threshold, dist[test_set], actual_issame[test_set])\n",
        "        _, _, accuracy[fold_idx] = calculate_accuracy(thresholds[best_threshold_index], dist[test_set], actual_issame[test_set])\n",
        "          \n",
        "        tpr = np.mean(tprs,0)\n",
        "        fpr = np.mean(fprs,0)\n",
        "    return tpr, fpr, accuracy\n",
        "\n",
        "def calculate_accuracy(threshold, dist, actual_issame):\n",
        "    predict_issame = np.less(dist, threshold)\n",
        "    tp = np.sum(np.logical_and(predict_issame, actual_issame))\n",
        "    fp = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n",
        "    tn = np.sum(np.logical_and(np.logical_not(predict_issame), np.logical_not(actual_issame)))\n",
        "    fn = np.sum(np.logical_and(np.logical_not(predict_issame), actual_issame))\n",
        "  \n",
        "    tpr = 0 if (tp+fn==0) else float(tp) / float(tp+fn)\n",
        "    fpr = 0 if (fp+tn==0) else float(fp) / float(fp+tn)\n",
        "    acc = float(tp+tn)/dist.size\n",
        "    return tpr, fpr, acc\n",
        "\n",
        "\n",
        "  \n",
        "def calculate_val(thresholds, embeddings1, embeddings2, actual_issame, far_target, nrof_folds=10, distance_metric=0, subtract_mean=False):\n",
        "    assert(embeddings1.shape[0] == embeddings2.shape[0])\n",
        "    assert(embeddings1.shape[1] == embeddings2.shape[1])\n",
        "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n",
        "    nrof_thresholds = len(thresholds)\n",
        "    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n",
        "    \n",
        "    val = np.zeros(nrof_folds)\n",
        "    far = np.zeros(nrof_folds)\n",
        "    \n",
        "    indices = np.arange(nrof_pairs)\n",
        "    \n",
        "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n",
        "        if subtract_mean:\n",
        "            mean = np.mean(np.concatenate([embeddings1[train_set], embeddings2[train_set]]), axis=0)\n",
        "        else:\n",
        "          mean = 0.0\n",
        "        dist = distance(embeddings1-mean, embeddings2-mean, distance_metric)\n",
        "      \n",
        "        # Find the threshold that gives FAR = far_target\n",
        "        far_train = np.zeros(nrof_thresholds)\n",
        "        for threshold_idx, threshold in enumerate(thresholds):\n",
        "            _, far_train[threshold_idx] = calculate_val_far(threshold, dist[train_set], actual_issame[train_set])\n",
        "        if np.max(far_train)>=far_target:\n",
        "            f = interpolate.interp1d(far_train, thresholds, kind='slinear')\n",
        "            threshold = f(far_target)\n",
        "        else:\n",
        "            threshold = 0.0\n",
        "    \n",
        "        val[fold_idx], far[fold_idx] = calculate_val_far(threshold, dist[test_set], actual_issame[test_set])\n",
        "  \n",
        "    val_mean = np.mean(val)\n",
        "    far_mean = np.mean(far)\n",
        "    val_std = np.std(val)\n",
        "    return val_mean, val_std, far_mean\n",
        "\n",
        "\n",
        "def calculate_val_far(threshold, dist, actual_issame):\n",
        "    predict_issame = np.less(dist, threshold)\n",
        "    true_accept = np.sum(np.logical_and(predict_issame, actual_issame))\n",
        "    false_accept = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n",
        "    n_same = np.sum(actual_issame)\n",
        "    n_diff = np.sum(np.logical_not(actual_issame))\n",
        "    val = float(true_accept) / float(n_same)\n",
        "    far = float(false_accept) / float(n_diff)\n",
        "    return val, far\n",
        "\n",
        "def store_revision_info(src_path, output_dir, arg_string):\n",
        "    try:\n",
        "        # Get git hash\n",
        "        cmd = ['git', 'rev-parse', 'HEAD']\n",
        "        gitproc = Popen(cmd, stdout = PIPE, cwd=src_path)\n",
        "        (stdout, _) = gitproc.communicate()\n",
        "        git_hash = stdout.strip()\n",
        "    except OSError as e:\n",
        "        git_hash = ' '.join(cmd) + ': ' +  e.strerror\n",
        "  \n",
        "    try:\n",
        "        # Get local changes\n",
        "        cmd = ['git', 'diff', 'HEAD']\n",
        "        gitproc = Popen(cmd, stdout = PIPE, cwd=src_path)\n",
        "        (stdout, _) = gitproc.communicate()\n",
        "        git_diff = stdout.strip()\n",
        "    except OSError as e:\n",
        "        git_diff = ' '.join(cmd) + ': ' +  e.strerror\n",
        "    \n",
        "    # Store a text file in the log directory\n",
        "    rev_info_filename = os.path.join(output_dir, 'revision_info.txt')\n",
        "    with open(rev_info_filename, \"w\") as text_file:\n",
        "        text_file.write('arguments: %s\\n--------------------\\n' % arg_string)\n",
        "        text_file.write('tensorflow version: %s\\n--------------------\\n' % tf.__version__)  # @UndefinedVariable\n",
        "        text_file.write('git hash: %s\\n--------------------\\n' % git_hash)\n",
        "        text_file.write('%s' % git_diff)\n",
        "\n",
        "def list_variables(filename):\n",
        "    reader = training.NewCheckpointReader(filename)\n",
        "    variable_map = reader.get_variable_to_shape_map()\n",
        "    names = sorted(variable_map.keys())\n",
        "    return names\n",
        "\n",
        "def put_images_on_grid(images, shape=(16,8)):\n",
        "    nrof_images = images.shape[0]\n",
        "    img_size = images.shape[1]\n",
        "    bw = 3\n",
        "    img = np.zeros((shape[1]*(img_size+bw)+bw, shape[0]*(img_size+bw)+bw, 3), np.float32)\n",
        "    for i in range(shape[1]):\n",
        "        x_start = i*(img_size+bw)+bw\n",
        "        for j in range(shape[0]):\n",
        "            img_index = i*shape[0]+j\n",
        "            if img_index>=nrof_images:\n",
        "                break\n",
        "            y_start = j*(img_size+bw)+bw\n",
        "            img[x_start:x_start+img_size, y_start:y_start+img_size, :] = images[img_index, :, :, :]\n",
        "        if img_index>=nrof_images:\n",
        "            break\n",
        "    return img\n",
        "\n",
        "def write_arguments_to_file(args, filename):\n",
        "    with open(filename, 'w') as f:\n",
        "        for key, value in iteritems(vars(args)):\n",
        "            f.write('%s: %s\\n' % (key, str(value)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/facenet/src/facenet.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DnpuxBqJg3A",
        "colab_type": "code",
        "outputId": "4dadbd2f-564c-4d73-d993-c740cf06dfa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        }
      },
      "source": [
        "!python facenet_fgsm.py"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-06-11 17:31:40.519245: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-06-11 17:31:40.519457: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x25651e0 executing computations on platform Host. Devices:\n",
            "2019-06-11 17:31:40.519488: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-06-11 17:31:40.699974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-06-11 17:31:40.700484: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2565e40 executing computations on platform CUDA. Devices:\n",
            "2019-06-11 17:31:40.700512: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-06-11 17:31:40.700857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 14.73GiB freeMemory: 14.60GiB\n",
            "2019-06-11 17:31:40.700882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-06-11 17:31:41.177034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-06-11 17:31:41.177100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-06-11 17:31:41.177119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-06-11 17:31:41.177439: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-06-11 17:31:41.177487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Model filename: models/facenet/20180402-114759/20180402-114759.pb\n",
            "WARNING:tensorflow:From /content/facenet/src/facenet.py:376: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.gfile.GFile.\n",
            "2019-06-11 17:31:45.268587: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "/content/cleverhans/cleverhans/attacks_tf.py:27: UserWarning: attacks_tf is deprecated and will be removed on 2019-07-18 or after. Code should import functions from their new locations directly.\n",
            "  warnings.warn(\"attacks_tf is deprecated and will be removed on 2019-07-18\"\n",
            "/content/cleverhans/cleverhans/compat.py:22: UserWarning: <function reduce_max_v1 at 0x7f238319e6a8> is deprecated. Switch to calling the equivalent function in tensorflow.  This function was originally needed as a compatibility layer for old versions of tensorflow,  but support for those versions has now been dropped.\n",
            "  warnings.warn(str(f) + \" is deprecated. Switch to calling the equivalent function in tensorflow. \"\n",
            "WARNING:tensorflow:From /content/cleverhans/cleverhans/attacks/attack.py:280: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "/content/cleverhans/cleverhans/compat.py:22: UserWarning: <function reduce_sum_v1 at 0x7f2383198950> is deprecated. Switch to calling the equivalent function in tensorflow.  This function was originally needed as a compatibility layer for old versions of tensorflow,  but support for those versions has now been dropped.\n",
            "  warnings.warn(str(f) + \" is deprecated. Switch to calling the equivalent function in tensorflow. \"\n",
            "WARNING:tensorflow:From /content/cleverhans/cleverhans/compat.py:79: calling softmax_cross_entropy_with_logits_v2_helper (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "dim is deprecated, use axis instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "FGSM step 1\n",
            "Accuracy: 96.69669669669669%\n",
            "Accuracy against adversarial examples for same person faces (dodging): 12.162162162162163%\n",
            "Accuracy against adversarial examples for different people faces (impersonation): 56.21621621621622%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93XOKBlakPPX",
        "colab_type": "code",
        "outputId": "d5d5b74d-04c7-4ca4-a4b0-aecda9195ef9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!python3 -c 'import tensorflow as tf; print(tf.__version__)' "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7h6yWTioXmg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad77e1f0-eb11-4477-d088-9a0355c12094"
      },
      "source": [
        "cd /"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNuG5dLSzxO2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "746a9134-5aae-4a5f-f262-bcb819741277"
      },
      "source": [
        "#To make a zipfile of a directory\n",
        "import shutil\n",
        "#shutil.make_archive(output_filename, 'zip', dir_name)\n",
        "shutil.make_archive(\"content.zip\", 'zip', \"/content\")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content.zip.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMNrVaoKs4Op",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp content.zip.zip /gdrive/'My Drive'/GEEEE/archive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVqEtixy0G1h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "33927d84-ff2a-4e9f-eaa8-158111125da3"
      },
      "source": [
        "#To download the file to your system\n",
        "from google.colab import files\n",
        "files.download('/content.zip.zip')\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-733763bcf9f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content.zip.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: Failed to download: [Exception... \"Out of Memory\"  nsresult: \"0x8007000e (NS_ERROR_OUT_OF_MEMORY)\"  location: \"<unknown>\"  data: no]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVGfdJEJ0OIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To upload files\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLq2V4gp8gnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To update a file on colab (Part I)\n",
        "#first cat the file\n",
        "!cat /path/to/file_to_udate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miIEZ--w8oiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To update a file on colab (Part II)\n",
        "%%writefile /path/to/file_to_udate\n",
        "## The following should be the code copied from above but with the modifications\n",
        "\"\"\"Helper for evaluation on the Labeled Faces in the Wild dataset \n",
        "\"\"\"\n",
        "\n",
        "# MIT License\n",
        "# \n",
        "# Copyright (c) 2016 David Sandberg"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}